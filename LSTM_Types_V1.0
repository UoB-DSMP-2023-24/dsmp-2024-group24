import pandas as pd 
from sklearn.preprocessing import MinMaxScaler
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM, Bidirectional
import matplotlib.pyplot as plt

gstock_data = pd.read_csv('E:/mini/output1.csv')

gstock_data = gstock_data[['Date', 'Opening', 'Closing']]
gstock_data['Date'] = pd.to_datetime(gstock_data['Date'].apply(lambda x: x.split()[0]))
gstock_data.set_index('Date', drop=True, inplace=True)

print(gstock_data.head())

Ms = MinMaxScaler()

# 使用 MinMaxScaler 对 gstock_data 中的数据进行归一化
gstock_data[gstock_data.columns] = Ms.fit_transform(gstock_data)


# 确定训练集大小，通常为数据集的80%
training_size = round(len(gstock_data) * 0.80)

# 划分训练集和测试集
train_data = gstock_data[:training_size]
test_data = gstock_data[training_size:]

def create_sequence(dataset):
    sequences = []
    labels = []
    start_idx = 0

    for stop_idx in range(50, len(dataset)):
        sequences.append(dataset.iloc[start_idx:stop_idx])
        labels.append(dataset.iloc[stop_idx])
        start_idx += 1

    return (np.array(sequences), np.array(labels))


# 创建训练集的序列数据和标签
train_seq, train_label = create_sequence(train_data)
print(train_seq.shape)

# 创建测试集的序列数据和标签
test_seq, test_label = create_sequence(test_data)
print(test_seq.shape)

# 创建 Sequential 模型
model = Sequential()

# 添加第一层 LSTM，return_sequences=True 表示返回完整的时间序列
model.add(LSTM(units=50, return_sequences=True, input_shape=(train_seq.shape[1], train_seq.shape[2])))

# 添加 Dropout 层，用于防止过拟合
model.add(Dropout(0.1))

# 添加第二层 LSTM
model.add(LSTM(units=50))

# 添加输出层，输出维度为2
model.add(Dense(2))

# 编译模型，使用均方误差作为损失函数，Adam 优化器，并使用平均绝对误差作为评估指标
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])

# 打印模型概要
model.summary()

# 训练模型，指定训练集、标签、迭代次数（epochs）、验证集
model.fit(train_seq, train_label, epochs=80, validation_data=(test_seq, test_label), verbose=1)

# 使用训练好的模型进行测试集预测
test_predicted = model.predict(test_seq)

# 假设 MMS 是 MinMaxScaler 的实例，使用其 inverse_transform 方法将预测结果逆转为原始数据范围
# MMS = MinMaxScaler()
test_inverse_predicted = Ms.inverse_transform(test_predicted)

# 合并实际和预测的数据
gs_slic_data = pd.concat([gstock_data.iloc[-1450:].copy(), pd.DataFrame(test_inverse_predicted, columns=['open_predicted', 'close_predicted'], index=gstock_data.iloc[-1450:].index)], axis=1)

# 将 'open' 和 'close' 列逆转为原始数据范围
gs_slic_data[['Opening', 'Closing']] = Ms.inverse_transform(gs_slic_data[['Opening', 'Closing']])

# 显示合并后的数据的前几行
gs_slic_data.head()

# 绘制 'open' 列的实际和预测数据
gs_slic_data[['Opening', 'open_predicted']].plot(figsize=(10, 6))
plt.xticks(rotation=45)
plt.xlabel('日期', size=15)
plt.ylabel('股票价格', size=15)
plt.title('实际 vs 预测的开盘价', size=15)
plt.show()

# 绘制 'close' 列的实际和预测数据
gs_slic_data[['Closing', 'close_predicted']].plot(figsize=(10, 6))
plt.xticks(rotation=45)
plt.xlabel('日期', size=15)
plt.ylabel('股票价格', size=15)
plt.title('实际 vs 预测的收盘价', size=15)
plt.show()
